{"cells":[{"metadata":{},"cell_type":"markdown","source":"add tile region","execution_count":null},{"metadata":{"id":"-yoHM3S8tIg_","trusted":true},"cell_type":"code","source":"DEBUG = False","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"2-yFBj-5MEmr","trusted":true},"cell_type":"code","source":"import os, random, glob, cv2, gc\nfrom termcolor import colored\nimport sys\nimport time\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import train_test_split\n\nimport torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\n\nimport albumentations as A\n\nfrom functools import partial\nimport scipy as sp\n\nfrom PIL import Image, ImageChops\n\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nfrom tqdm.notebook import tqdm\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport albumentations as A","execution_count":null,"outputs":[]},{"metadata":{"id":"teT-P-ZFt_tt","trusted":true},"cell_type":"code","source":"Image.MAX_IMAGE_PIXELS = 933120000","execution_count":null,"outputs":[]},{"metadata":{"id":"x6ejGLVetIhF","trusted":true},"cell_type":"code","source":"GRAY_TR = 235\nN_TR = 0.85\nWHITE_TR = 0.95\n\nV = 4 # efn version (0-7)\nREGION = 0 # cut region (0-3)\n\nclass config:\n    SZ = 256    # not used, just to declare start point, \n    N = 36      # not used, just to declare start point, \n    LEVEL = 1   # not used, just to declare start point, \n    \n    IMG_SIZE = 800\n    BS = 4\n    SEED = 2020\n    LR = 0.0001\n    LOG = f'./efnb{V}-log.txt'","execution_count":null,"outputs":[]},{"metadata":{"id":"iLhTBmUxtIhJ","trusted":true},"cell_type":"code","source":"# seed\n\ndef seed_everything(seed=2020):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(config.SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"x5VQKM5KMEmz","outputId":"d2b773e6-db13-4c23-a1ea-45075af1c925","trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"686l5iiMMEm5","outputId":"aafe0fdf-b38f-4b49-8bb8-da365b329a46","trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","execution_count":null,"outputs":[]},{"metadata":{"id":"GudK3il7MEnB"},"cell_type":"markdown","source":"# Data","execution_count":null},{"metadata":{"id":"3epnwhh8MEnB","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/pandadf/train.csv')\ndf = df.iloc[:1000] if DEBUG else df","execution_count":null,"outputs":[]},{"metadata":{"id":"F0u0nqFXMEnE","outputId":"5c06dc41-b33b-453a-c2ae-8278548c6473","trusted":true},"cell_type":"code","source":"# shuffle\ndf = shuffle(df)\n\n# split\ntrain_df = df[df.split != 0]\nval_df = df[df.split == 0]\nn = len(val_df) // 2\ntest_df = val_df.iloc[:n]\nval_df = val_df.iloc[n:]\n\n\nlen(train_df), len(val_df), len(test_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"fr6WJOOLMEnG","outputId":"fecff265-fb30-47b1-fe32-b5babd203d35","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"XT8944SFMEnI"},"cell_type":"markdown","source":"# Augmentation","execution_count":null},{"metadata":{"id":"4_owBQZXMEnI","trusted":true},"cell_type":"code","source":"train_transforms = A.Compose([A.Transpose(p=0.5), \n                             A.VerticalFlip(p=0.5),\n                             A.HorizontalFlip(p=0.5)])\nval_transforms = A.Compose([])","execution_count":null,"outputs":[]},{"metadata":{"id":"prEvPZqbMEnM"},"cell_type":"markdown","source":"# Dataset","execution_count":null},{"metadata":{"id":"oVhtDdaJtIha","trusted":true},"cell_type":"code","source":"def get_tiles(img, SZ=256, N=36):\n    '''\n    dynamically select SZ and N\n    img: numpy array since this image has been processed by select_level, remove_gray, crop, and transpose\n    Return \n        tiles, SZ, N\n    '''\n    \n    # pad img\n    h, w, c = img.shape\n    pad_h = (SZ - h % SZ) % SZ \n    pad_w = (SZ - w % SZ) % SZ \n\n    img2 = np.pad(img, [[pad_h // 2, pad_h - pad_h // 2], \n                        [pad_w // 2, pad_w - pad_w//2], \n                        [0,0]], constant_values=255)\n    \n    # choose tiles\n    img3 = img2.reshape(\n        img2.shape[0] // SZ,\n        SZ,\n        img2.shape[1] // SZ,\n        SZ,\n        3\n    )\n    \n    new_row, new_col = img3.shape[0], img3.shape[2]\n    img3 = img3.transpose(0, 2, 1, 3, 4).reshape(-1, SZ, SZ, 3) # (783, 256, 256, 3)\n    info = (img3.reshape(img3.shape[0],-1).sum(-1) < WHITE_TR * SZ*SZ*3*255).sum() # how many tiles are not white\n    \n    # get new N\n    possible_N = int(np.sqrt(info))**2\n    if N < possible_N:\n        N = possible_N\n        \n    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:N]\n    tiles = img3[idxs]\n        \n    return tiles, SZ, N, info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_tiles(img, SZ=256, N=36):\n    tiles, SZ, N, info = get_tiles(img, SZ=SZ, N=N)\n\n    \n    # too much white tiles\n    while info <= int(N_TR * N) and SZ > 64:\n        SZ = SZ // 2\n        tiles, SZ, N, info = get_tiles(img, SZ=SZ, N=N)\n        \n        \n    # pad \n    # for example 32 < 30(0.85*36) \n    if tiles.shape[0] < N:\n        tiles = np.pad(tiles, [ [0, N-len(tiles)], [0,0],[0,0],[0,0]], constant_values=255)\n        \n        \n    return tiles, SZ, N, info","execution_count":null,"outputs":[]},{"metadata":{"id":"ZuVW0J9sMEnM","trusted":true},"cell_type":"code","source":"class MyTrainDataset(Dataset):\n    def __init__(self, df, split='train', shuffle_df=False, shuffle_tiles=False, region=0):\n        super().__init__()\n        \n        if shuffle_df:\n            df = shuffle(df)\n        self.df = df.reset_index(drop=True)\n        \n        self.split = split\n        self.shuffle_tiles = shuffle_tiles\n        \n        self.region = region\n            \n        \n    def __len__(self):\n        return len(self.df)\n    \n    \n    def __getitem__(self, idx):\n        \n        # read img\n        name = self.df.image_id[idx] \n        folder = self.df.folder[idx]\n        path = f'../input/pandacroppedlevel1{folder}/train{folder}/{name}.jpeg'\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n\n\n        tiles, SZ, N, info = find_tiles(img) # find suitable tiles, SZ, N\n        \n\n        # apply transform to each img\n        imgs = []\n        for t in tiles:\n            if self.split == 'train':\n                t_aug = train_transforms(**{'image': t})['image']\n            elif self.split == 'val':\n                t_aug = val_transforms(**{'image': t})['image']\n                \n            imgs.append(t_aug) \n        \n        \n        # shuffle tiles\n        if self.shuffle_tiles:\n            imgs = shuffle(imgs)\n     \n        # concat\n        n = int(np.sqrt(N)) # new Z\n        images = np.zeros((SZ*n, SZ*n, 3), dtype=np.int32) # new SZ\n        for i in range(n):\n            for j in range(n):\n                images[i*SZ : (i+1)*SZ, j*SZ : (j+1)*SZ, :] = imgs[i*n+j]\n        \n            \n        # normalize \n        images = 255 - images # reverse \n        if self.split == 'train':\n            images = train_transforms(image=images)['image']\n        images = A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])(image=images)['image']\n        \n        # get region, 4 in total\n        images = cv2.resize(images, (2*config.IMG_SIZE, 2*config.IMG_SIZE))\n        \n        if self.region == 0: # left up\n            images = images[:800, :800, :]\n        elif self.region == 1:  # right up\n            images = images[:800, 800:, :]\n        elif self.region == 1:\n            images = images[800:, :800, :]\n        elif self.region == 1:\n            images = images[800:, 800:, :]\n    \n        images = torch.tensor(images).permute(2, 0, 1)\n        \n        label = torch.tensor(self.df.isup_grade[idx])\n        return images, label","execution_count":null,"outputs":[]},{"metadata":{"id":"MEFMs-taMEnO","trusted":true},"cell_type":"code","source":"# test dataset\nif DEBUG:\n    train_ds = MyTrainDataset(train_df, 'train', shuffle_tiles=True, region=0)\n    x, y = train_ds[0]\n    print(x.shape)\n    plt.imshow((x*0.5+0.5).permute(1, 2, 0).numpy())\n    plt.title(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(region=0):\n    train_ds = MyTrainDataset(train_df, 'train', shuffle_tiles=True, region=region)\n    train_dl = DataLoader(train_ds, batch_size=config.BS, shuffle=True, drop_last=False) # use 32 means 2 images per batch, don't shuffle to preserve \n\n    val_ds = MyTrainDataset(val_df, 'val', shuffle_tiles=False, region=region)\n    val_dl = DataLoader(val_ds, batch_size=config.BS, shuffle=False, drop_last=False)\n\n    test_ds = MyTrainDataset(test_df, 'val', shuffle_tiles=False, region=region)\n    test_dl = DataLoader(test_ds, batch_size=config.BS, shuffle=False, drop_last=False)\n    \n    return train_dl, val_dl, test_dl","execution_count":null,"outputs":[]},{"metadata":{"id":"W97fcYNzMEnP","trusted":true},"cell_type":"code","source":"train_dl, val_dl, test_dl = get_data(0)","execution_count":null,"outputs":[]},{"metadata":{"id":"WTzlw_F1MEnR","trusted":true},"cell_type":"code","source":"# test dl\nif DEBUG:\n    x, y = next(iter(train_dl))\n    plt.imshow((x[0]*0.5+0.5).permute(1, 2, 0).numpy())\n    plt.title(y[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"kgiffLk8MEnS"},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{"id":"_pg8o72DtIhl","outputId":"342eb537-c0e3-400a-d31c-ce4d14ffd7fa","trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{"id":"zxzdcF3ttIhn","trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\nclass MyModel(nn.Module):\n    def __init__(self, backbone=f'efficientnet-b{V}'):\n        super().__init__()\n        \n        self.base = EfficientNet.from_pretrained(backbone)\n        self.fc = nn.Linear(self.base._fc.in_features, 1)\n        self.base._fc = nn.Identity()\n    \n    def forward(self, x):\n        x = self.base(x)\n        x = self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"id":"G6q-SCnHtIho","trusted":true},"cell_type":"code","source":"if DEBUG:\n    model = MyModel()\n    x = torch.randn(2, 3, 800, 800) # for b4, it can only accepts 512\n    y = model(x)\n    print(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"aZZISN79tIhq","outputId":"f2161922-247e-4b14-c3cf-bbe633ec9512","trusted":true},"cell_type":"code","source":"model = MyModel()\nmodel = model.to(device)\nmodel.load_state_dict(torch.load('../input/pandaefnb4region/efnb4-0-1-0.8114.pth', map_location=device))\n\noptimizer = optim.Adam(model.parameters(), lr=config.LR)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=5, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"4fUKc4jwMEnX","trusted":true},"cell_type":"code","source":"# freeze \n# def freeze_until(model, name):\n#     flag = False\n#     for n, p in model.named_parameters():\n#         if n == name:\n#             flag = True\n#         p.requires_grad = flag\n# freeze_until(model, 'model.layer4.2.conv1.weight')","execution_count":null,"outputs":[]},{"metadata":{"id":"HhHxQFPaMEnZ"},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{"id":"nh5unJkuMEna","trusted":true},"cell_type":"code","source":"class OptimizedRounder():\n    def __init__(self):\n        self.coef_ = [0.5, 1.5, 2.5, 3.5, 4.5]\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            elif pred >= coef[3] and pred < coef[4]:\n                X_p[i] = 4\n            else:\n                X_p[i] = 5\n\n        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef=[0.5, 1.5, 2.5, 3.5, 4.5]):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            elif pred >= coef[3] and pred < coef[4]:\n                X_p[i] = 4\n            else:\n                X_p[i] = 5\n        return X_p\n\n    def coefficients(self):\n        '''use after self.fit or error throws'''\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"id":"24Bhu4CbQ3pj","trusted":true},"cell_type":"code","source":"rounder = OptimizedRounder()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"ysNGssXYMEnb","trusted":true},"cell_type":"code","source":"def train_on(epoch, train_dl):\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    model.train()\n    \n    loss_epoch = []\n    preds_epoch = []\n    y_epoch = []\n    bar = tqdm(enumerate(train_dl), total=len(train_dl))\n    for i, (x, y) in bar:\n        x = x.to(device, dtype=torch.float32)\n        y = y.to(device, dtype=torch.float32)\n\n        y_preds = model(x) # [batch, 1]\n        y_preds = y_preds.view(-1) #[batch,]\n        \n        # get metrics\n        loss = nn.MSELoss()(y_preds, y)\n\n        # update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # add\n        y_np = y.cpu().detach().numpy()\n        y_preds_np = rounder.predict(y_preds.cpu().detach().numpy())\n        loss_np = loss.cpu().detach().numpy()\n        \n        # add\n        preds_epoch.append(y_preds_np)\n        y_epoch.append(y_np)\n        loss_epoch.append(loss_np)\n    \n        \n        c = cohen_kappa_score(y_np, y_preds_np, weights='quadratic')\n        bar.set_description('loss: %.4f, cohen: %.4f' % (loss_np, c))\n        \n            \n        # clean\n        del x, y, y_preds, loss, y_np, y_preds_np, loss_np\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        \n    cohen = cohen_kappa_score(np.concatenate(preds_epoch), \n                              np.concatenate(y_epoch), \n                              weights='quadratic')\n    \n    print('Epoch: %d, Loss: %.4f, Cohen: %.4f' % (epoch, np.mean(loss_epoch), cohen))\n    return np.mean(loss_epoch), cohen\n","execution_count":null,"outputs":[]},{"metadata":{"id":"3mJF8Fp4MEnc","outputId":"45d026b1-f6a6-4689-d013-25632950c433","trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"lJmXBCfGMEnd","trusted":true},"cell_type":"code","source":"if DEBUG:\n    train_on(1, train_dl)","execution_count":null,"outputs":[]},{"metadata":{"id":"XVbm0rdrMEnf","trusted":true},"cell_type":"code","source":"def val_on(epoch, dl):\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    model.eval()\n    \n    loss_epoch = []\n    preds_epoch = []\n    y_epoch = []\n    bar = tqdm(enumerate(dl), total=len(dl))\n    with torch.no_grad():\n        for i, (x, y) in bar:\n            x = x.to(device, dtype=torch.float32)\n            y = y.to(device, dtype=torch.float32)\n            \n            y_preds = model(x).view(-1)\n\n            # get metrics\n            loss = nn.MSELoss()(y_preds, y)\n\n            # add\n            y_preds_np = y_preds.cpu().detach().numpy()\n            y_np = y.cpu().detach().numpy()\n            loss_np = loss.cpu().detach().numpy()\n            \n            loss_epoch.append(loss_np)\n            preds_epoch.append(y_preds_np)\n            y_epoch.append(y_np)\n            \n            \n            # get cohen\n            c = cohen_kappa_score(rounder.predict(y_preds_np), y_np, weights='quadratic')\n            bar.set_description('loss: %.4f, cohen: %.4f' % (loss_np, c))\n\n        \n            # clean\n            del x, y, y_preds, loss, y_np, y_preds_np, loss_np, c\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n\n    # cohen\n    preds_epoch = np.concatenate(preds_epoch)\n    y_epoch = np.concatenate(y_epoch)\n    \n    rounder.fit(preds_epoch, y_epoch)\n    coef = rounder.coefficients()\n    preds_epoch = rounder.predict(preds_epoch, coef)\n    cohen = cohen_kappa_score(preds_epoch, y_epoch, weights='quadratic')\n    \n    print('Epoch: %d, Loss: %.4f, Cohen: %.4f' % (epoch, np.mean(loss_epoch), cohen))\n\n    return np.mean(loss_epoch), cohen, coef\n               ","execution_count":null,"outputs":[]},{"metadata":{"id":"yatGooB0NqGJ","trusted":true},"cell_type":"code","source":"if DEBUG:\n    val_on(1, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# should be put outside \nbest_cohen = [0.8114] # last best score","execution_count":null,"outputs":[]},{"metadata":{"id":"jn-RseODMEng","trusted":true},"cell_type":"code","source":"def train(region, epochs, train_dl, val_dl):\n    \n    for e in range(epochs):\n        train_loss, train_cohen = train_on(e, train_dl)\n        val_loss, val_cohen, coef = val_on(e, val_dl)\n        \n        # adjust lr\n        scheduler.step(val_loss)\n\n        # write to log\n        with open(config.LOG, 'a') as f:\n            f.write(time.ctime() + f' Epoch: {e}, Train loss: {(train_loss):.4f}, Train cohen: {(train_cohen):.4f}\\n   Val loss: {(val_loss):.4f}, Val cohen:{(val_cohen):.4f}, Coef: {coef} \\n\\n')\n            \n        # save best\n        best_cohen.append(val_cohen)\n        if val_cohen >= max(best_cohen):\n            print('save best model')\n            torch.save(model.state_dict(), f'efnb{V}-{region}-best.pth')\n            \n        torch.save(model.state_dict(), f'./efnb{V}-{region}-{e}.pth')\n        \n    torch.save(model.state_dict(), f'./efnb{V}-{region}-final.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"SIGTzkCJMEnh","outputId":"a98e235b-8002-4e41-fdb6-cab02d9251b6","trusted":true},"cell_type":"code","source":"train_dl, val_dl, test_dl = get_data(region=0)\ntrain(0, 10, train_dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.load_state_dict(torch.load(f'efnb{V}-6.pth'))","execution_count":null,"outputs":[]},{"metadata":{"id":"WAc9HUJ4MEnj","outputId":"73e5cfb2-8662-40c9-d12c-20048d549817","trusted":true},"cell_type":"code","source":"val_on(1, test_dl) \n# 0.8858\n# [0.51885345, 1.53662393, 2.44524873, 3.61225587, 4.29971003]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}