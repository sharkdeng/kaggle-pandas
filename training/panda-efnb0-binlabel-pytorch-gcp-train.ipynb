{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of This Baseline\n",
    "\n",
    "* Using tiling method based on https://www.kaggle.com/iafoss/panda-16x128x128-tiles\n",
    "    * Simply setting the `N = 36` and `sz=256` then extract from median resolution\n",
    "* Create 6x6 big image from 36 tiles\n",
    "* Efficientnet-B0\n",
    "* Binning label\n",
    "    * E.g.\n",
    "        * `label = [0,0,0,0,0]` means `isup_grade = 0`\n",
    "        * `label = [1,1,1,0,0]` means `isup_grade = 3`\n",
    "        * `label = [1,1,1,1,1]` means `isup_grade = 5`\n",
    "* BCE loss\n",
    "* Augmentation on both tile level and big image level\n",
    "* CosineAnnealingLR for one round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
      "  Cloning https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to /tmp/pip-req-build-gl2k0cl_\n",
      "  Running command git clone -q https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-gl2k0cl_\n",
      "Requirement already satisfied (use --upgrade to upgrade): warmup-scheduler==0.3.2 from git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git in /opt/conda/lib/python3.7/site-packages\n",
      "Building wheels for collected packages: warmup-scheduler\n",
      "  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3.2-py3-none-any.whl size=3881 sha256=2b0c556991fb526e8b52253704e5f9c6b1443cf3d7208f36c4bc3876ada54774\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8kaks6ct/wheels/bf/81/52/0e3bc0b645a339f94c76b4dcb8c8b7a5f588a614f5add83b9f\n",
      "Successfully built warmup-scheduler\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet-pytorch in /opt/conda/lib/python3.7/site-packages (0.6.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warmup_scheduler import GradualWarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image, ImageChops\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', Image.DecompressionBombWarning)\n",
    "\n",
    "import time\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
    "from torch.optim.sgd import SGD\n",
    "from torch import FloatTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9289, 664, 663)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# shuffle\n",
    "df = shuffle(df)\n",
    "\n",
    "# split\n",
    "train_df = df[df.split != 0]\n",
    "train_df = train_df.sample(1000) if DEBUG else train_df\n",
    "val_df = df[df.split == 0]\n",
    "n = len(val_df) // 2\n",
    "test_df = val_df.iloc[:n]\n",
    "val_df = val_df.iloc[n:]\n",
    "\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>split</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>283b3a40795ae1992f0ddd56a55c396a</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>66ed3b7961aea86a4a44a6798884b6bc</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>e2c1421a3794ba9dc1673c6509628485</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>5ee927ed5d354f5f72e5d341276eb5be</td>\n",
       "      <td>radboud</td>\n",
       "      <td>3</td>\n",
       "      <td>4+3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8664</th>\n",
       "      <td>ed9a38a9f1dfa898e536cd91f13d98b1</td>\n",
       "      <td>radboud</td>\n",
       "      <td>3</td>\n",
       "      <td>4+3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_id data_provider  isup_grade  \\\n",
       "2552  283b3a40795ae1992f0ddd56a55c396a    karolinska           1   \n",
       "1552  66ed3b7961aea86a4a44a6798884b6bc       radboud           4   \n",
       "8438  e2c1421a3794ba9dc1673c6509628485    karolinska           0   \n",
       "1654  5ee927ed5d354f5f72e5d341276eb5be       radboud           3   \n",
       "8664  ed9a38a9f1dfa898e536cd91f13d98b1       radboud           3   \n",
       "\n",
       "     gleason_score  split  folder  \n",
       "2552           3+3      2       3  \n",
       "1552           4+4      4       1  \n",
       "8438           0+0      7       1  \n",
       "1654           4+3      4       1  \n",
       "8664           4+3      4       3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAY_TR = 235\n",
    "N_TR = 0.85\n",
    "WHITE_TR = 0.95\n",
    "\n",
    "class config:\n",
    "    SZ = 256    # not used, just to declare start point, \n",
    "    N = 36      # not used, just to declare start point, \n",
    "    LEVEL = 1   # not used, just to declare start point, \n",
    "    \n",
    "    IMG_SIZE = 1536\n",
    "    BS = 2 # batch size\n",
    "    NUM_WORKERS = 4\n",
    "    CLASSES = 5\n",
    "    BASE = 'efficientnet-b0'\n",
    "    LR = 3e-4 # learning rate\n",
    "    EPOCHS = 1 if DEBUG else 10\n",
    "    SEED = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed\n",
    "\n",
    "def seed_everything(seed=2020):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, backbone, out_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.enet = EfficientNet.from_name(backbone)\n",
    "        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n",
    "        self.enet._fc = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        return self.enet(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extract(x)\n",
    "        x = self.myfc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "if DEBUG:\n",
    "    \n",
    "    model = MyModel('efficientnet-b0', 5)\n",
    "    x = FloatTensor(np.random.randn(5, 3, 512, 512))\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "\n",
    "    del model, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(img, SZ=256, N=36):\n",
    "    '''\n",
    "    dynamically select SZ and N\n",
    "    img: numpy array since this image has been processed by select_level, remove_gray, crop, and transpose\n",
    "    Return \n",
    "        tiles, SZ, N\n",
    "    '''\n",
    "    \n",
    "    # pad img\n",
    "    h, w, c = img.shape\n",
    "    pad_h = (SZ - h % SZ) % SZ \n",
    "    pad_w = (SZ - w % SZ) % SZ \n",
    "\n",
    "    img2 = np.pad(img, [[pad_h // 2, pad_h - pad_h // 2], \n",
    "                        [pad_w // 2, pad_w - pad_w//2], \n",
    "                        [0,0]], constant_values=255)\n",
    "    \n",
    "    # choose tiles\n",
    "    img3 = img2.reshape(\n",
    "        img2.shape[0] // SZ,\n",
    "        SZ,\n",
    "        img2.shape[1] // SZ,\n",
    "        SZ,\n",
    "        3\n",
    "    )\n",
    "    \n",
    "    new_row, new_col = img3.shape[0], img3.shape[2]\n",
    "    img3 = img3.transpose(0, 2, 1, 3, 4).reshape(-1, SZ, SZ, 3) # (783, 256, 256, 3)\n",
    "    info = (img3.reshape(img3.shape[0],-1).sum(-1) < WHITE_TR * SZ*SZ*3*255).sum() # how many tiles are not white\n",
    "    \n",
    "    # get new N\n",
    "    possible_N = int(np.sqrt(info))**2\n",
    "    if N < possible_N:\n",
    "        N = possible_N\n",
    "        \n",
    "    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:N]\n",
    "    tiles = img3[idxs]\n",
    "        \n",
    "    return tiles, SZ, N, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tiles(img, SZ=256, N=36):\n",
    "    tiles, SZ, N, info = get_tiles(img, SZ=SZ, N=N)\n",
    "\n",
    "    \n",
    "    # too much white tiles\n",
    "    # smallest SZ is 64\n",
    "    while info <= int(N_TR * N) and SZ > 64:\n",
    "        SZ = SZ // 2\n",
    "        tiles, SZ, N, info = get_tiles(img, SZ=SZ, N=N)\n",
    "        \n",
    "        \n",
    "    # pad \n",
    "    # for example 32 < 30(0.85*36) \n",
    "    if tiles.shape[0] < N:\n",
    "        tiles = np.pad(tiles, [ [0, N-len(tiles)], [0,0],[0,0],[0,0]], constant_values=255)\n",
    "        \n",
    "        \n",
    "    return tiles, SZ, N, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([A.Transpose(p=0.5), \n",
    "                             A.VerticalFlip(p=0.5),\n",
    "                             A.HorizontalFlip(p=0.5)])\n",
    "val_transforms = A.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainDataset(Dataset):\n",
    "    def __init__(self, df, split='train', shuffle_df=False, shuffle_tiles=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if shuffle_df:\n",
    "            df = shuffle(df)\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "        self.split = split\n",
    "        self.shuffle_tiles = shuffle_tiles\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # read img\n",
    "        name = self.df.image_id[idx] \n",
    "        folder = self.df.folder[idx]\n",
    "        myzip = ZipFile(f'pandacroppedlevel1{folder}.zip')\n",
    "        path = f'train{folder}/{name}.jpeg'\n",
    "        img = myzip.open(path)\n",
    "        img = Image.open(img)\n",
    "        img = np.array(img)  \n",
    "        \n",
    "        \n",
    "        tiles, SZ, N, info = find_tiles(img) # find suitable tiles, SZ, N\n",
    "        \n",
    "\n",
    "        # apply transform to each img\n",
    "        imgs = []\n",
    "        for t in tiles:\n",
    "            if self.split == 'train':\n",
    "                t_aug = train_transforms(**{'image': t})['image']\n",
    "            elif self.split == 'val':\n",
    "                t_aug = val_transforms(**{'image': t})['image']\n",
    "                \n",
    "            imgs.append(t_aug) \n",
    "        \n",
    "        \n",
    "        # shuffle tiles\n",
    "        if self.shuffle_tiles:\n",
    "            imgs = shuffle(imgs)\n",
    "     \n",
    "        # concat\n",
    "        n = int(np.sqrt(N)) # new Z\n",
    "        images = np.zeros((SZ*n, SZ*n, 3), dtype=np.int32) # new SZ\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                images[i*SZ : (i+1)*SZ, j*SZ : (j+1)*SZ, :] = imgs[i*n+j]\n",
    "        \n",
    "            \n",
    "        # normalize \n",
    "        images = 255 - images # reverse \n",
    "        if self.split == 'train':\n",
    "            images = train_transforms(image=images)['image']\n",
    "        images = A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])(image=images)['image']\n",
    "        \n",
    "        # resize \n",
    "        images = cv2.resize(images, (config.IMG_SIZE, config.IMG_SIZE))\n",
    "        images = torch.tensor(images).permute(2, 0, 1)\n",
    "        \n",
    "        # ordinal regression\n",
    "        label = np.zeros(5).astype(np.float32)\n",
    "        origin_label = self.df.isup_grade[idx]\n",
    "        label[:origin_label] = 1.\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_tiles\n",
    "if DEBUG:\n",
    "    ds = MyTrainDataset(df, shuffle_tiles=True)  \n",
    "    \n",
    "    # show samples\n",
    "    fig, ax = plt.subplots(5, 5, figsize=(20, 20))\n",
    "    for i in range(5):\n",
    "        for j in range(5):  \n",
    "            x, y = ds[i*5+j]\n",
    "            ax[i, j].imshow(x.permute(1, 2, 0)*0.5+0.5)\n",
    "            ax[i, j].set_title(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on(dl, optimizer):\n",
    "\n",
    "    # 1 clean\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # 3 analysis\n",
    "    loss_epoch = []\n",
    "    y_preds_epoch = []\n",
    "    y_epoch = []\n",
    "    \n",
    "    bar = tqdm(dl, total=len(dl))\n",
    "    for (x, y) in bar:\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_preds = model(x)\n",
    "        loss = nn.BCEWithLogitsLoss()(y_preds, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # cohen\n",
    "        y_preds_np = y_preds.sigmoid().sum(1).detach().cpu().round()\n",
    "        y_np = y.sum(1).detach().cpu().numpy()\n",
    "        cohen = cohen_kappa_score(y_preds_np, y_np, weights='quadratic')\n",
    "            \n",
    "            \n",
    "        # add\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        \n",
    "        loss_epoch.append(loss_np)\n",
    "        y_epoch.append(y_np)\n",
    "        y_preds_epoch.append(y_preds_np)\n",
    "        \n",
    "        bar.set_description('loss: %.4f, cohen: %.4f' % (loss_np, cohen))\n",
    "        \n",
    "        \n",
    "        # clean\n",
    "        del x, y, y_preds, loss, loss_np, y_preds_np, y_np, cohen\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    # get train cohen\n",
    "    y_epoch = np.concatenate(y_epoch)\n",
    "    y_preds_epoch = np.concatenate(y_preds_epoch)\n",
    "    train_cohen = cohen_kappa_score(y_preds_epoch, y_epoch, weights='quadratic')\n",
    "\n",
    "    return np.mean(loss_epoch), train_cohen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_on(dl):\n",
    "\n",
    "    # 1 clean\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # 3 analysis\n",
    "    loss_epoch = []\n",
    "    y_epoch = []\n",
    "    y_preds_epoch = []\n",
    "\n",
    "    bar = tqdm(dl, total=len(dl))\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in bar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_preds = model(x)\n",
    "\n",
    "            loss = nn.BCEWithLogitsLoss()(y_preds, y)\n",
    "            \n",
    "\n",
    "            # get cohen\n",
    "            y_preds_np = y_preds.sigmoid().sum(1).detach().cpu().numpy().round()\n",
    "            y_np = y.sum(1).detach().cpu().numpy()\n",
    "            cohen = cohen_kappa_score(y_preds_np, y_np, weights='quadratic')\n",
    "            \n",
    "            bar.set_description('Loss: %.4f, cohen: %.4f' % (loss, cohen))\n",
    "            \n",
    "            # add\n",
    "            y_preds_epoch.append(y_preds_np)\n",
    "            y_epoch.append(y_np)\n",
    "            \n",
    "            loss_np = loss.detach().cpu().numpy()\n",
    "            loss_epoch.append(loss_np)\n",
    "            \n",
    "            # clean\n",
    "            del y, y_preds, y_np, y_preds_np, loss, loss_np\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "\n",
    "    # get val cohen\n",
    "    y_epoch = np.concatenate(y_epoch)\n",
    "    y_preds_epoch = np.concatenate(y_preds_epoch)\n",
    "    val_cohen = cohen_kappa_score(y_preds_epoch, y_epoch, weights='quadratic')\n",
    "    \n",
    "#     val_cohen_k = cohen_kappa_score(y_preds_epoch[val_df['data_provider'] == 'karolinska'], val_df[val_df['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n",
    "#     val_cohen_r = cohen_kappa_score(y_preds_epoch[val_df['data_provider'] == 'radboud'], val_df[val_df['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n",
    "#     print('val_cohen', val_cohen, 'val_cohen_k', val_cohen_k, 'val_cohen_r', val_cohen_r)\n",
    "\n",
    " \n",
    "    return np.mean(loss_epoch), val_cohen\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader & Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fold):\n",
    "\n",
    "    train_ds = MyTrainDataset(train_df, split='train', shuffle_tiles=True)  \n",
    "    val_ds = MyTrainDataset(val_df, split='val', shuffle_tiles=True)  \n",
    "\n",
    "    train_dl = DataLoader(train_ds, \n",
    "                          batch_size=config.BS, \n",
    "                          sampler=RandomSampler(train_df), \n",
    "                          num_workers=config.NUM_WORKERS,\n",
    "                          drop_last = True)\n",
    "    val_dl = DataLoader(val_ds, \n",
    "                        batch_size=config.BS, \n",
    "                        sampler=SequentialSampler(val_df), \n",
    "                        num_workers=config.NUM_WORKERS,\n",
    "                        drop_last=True)\n",
    "    \n",
    "    print(len(train_ds), len(val_ds))\n",
    "    return train_dl, val_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important for resuming training since lr would change\n",
    "\n",
    "def save_model(path):\n",
    "    ck = {'state_dict': model.state_dict(), \n",
    "          'optim': optimizer.state_dict()}\n",
    "    torch.save(ck, path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    ck = torch.load(path)\n",
    "    model.load_state_dict(ck['state_dict'])\n",
    "    optimizer.load_state_dict(ck['optim'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, config.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cohen = 0.8640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9289 664\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = get_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(config.BASE, out_dim=config.CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, config.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    global best_cohen\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        scheduler.step(epoch-1)\n",
    "\n",
    "        \n",
    "        train_loss, train_cohen = train_on(train_dl, optimizer)\n",
    "        print(f'Epoch: {epoch}, train_loss: {train_loss:.4f}, train_cohen: {train_cohen:.4f}')\n",
    "\n",
    "        \n",
    "        val_loss, val_cohen = val_on(val_dl)\n",
    "        print(f'Epoch: {epoch}, val_loss: {val_loss:.4f}, val_cohen: {val_cohen:.4f}')\n",
    "\n",
    "        \n",
    "        content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.4f}, train cohen: {(train_cohen):.4f} val loss: {val_loss:.4f}, cohen: {(val_cohen):.4f}'\n",
    "        with open(f'efnb0_log.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        # to avoid machine crash\n",
    "        save_model(f'efnb0-{epoch}.pth')\n",
    "\n",
    "        # best cohen\n",
    "        if val_cohen > best_cohen:\n",
    "            print('Save model')\n",
    "            save_model(f'efnb0-best.pth')\n",
    "            best_cohen = val_cohen\n",
    "\n",
    "\n",
    "    save_model(f'efnb0_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model('efnb0-3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00204ca9c1ee42fba3b6a4d89e32bd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2529182, 0.8896315733484628)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_on(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  4 05:55:30 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f16efd39f264add976f5695d90ffe97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:620: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train_loss: 0.1557, train_cohen: 0.9166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641476a4ff4b47a4a690e2c280a8d35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, val_loss: 0.2884, val_cohen: 0.8771\n",
      "Save model\n",
      "Sat Jul  4 07:04:16 2020 Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec4ec6516dc40969d82da7908d84d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train_loss: 0.1560, train_cohen: 0.9163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a455d32d73c4317bb36867202881929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, val_loss: 0.4776, val_cohen: 0.8399\n",
      "Sat Jul  4 08:12:54 2020 Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a982552c03a4f8b9f6f9c49f8a099d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train_loss: 0.1509, train_cohen: 0.9200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e86a7c602241a381b36e9d584b1b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, val_loss: 0.2529, val_cohen: 0.8896\n",
      "Save model\n",
      "Sat Jul  4 09:21:33 2020 Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669ff0083d7f4eb0b1b9a4be4ac4477e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train_loss: 0.1379, train_cohen: 0.9302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b33df72b3b4997a4b1e2e15ed6ac61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, val_loss: 0.2921, val_cohen: 0.8830\n",
      "Sat Jul  4 10:30:07 2020 Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d670f218fda4df39cf6f21fb3438d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train_loss: 0.1264, train_cohen: 0.9397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29248bdb56842d28a9c49f1dcebe461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, val_loss: 0.3027, val_cohen: 0.8729\n",
      "Sat Jul  4 11:38:42 2020 Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a658440d774b99b4489e223b68e4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train_loss: 0.1117, train_cohen: 0.9505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cb52d03f8b4b68a835f41ccf25447a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, val_loss: 0.3840, val_cohen: 0.8783\n",
      "Sat Jul  4 12:47:26 2020 Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cc927171dc40b09f11255add7d92f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train_loss: 0.0969, train_cohen: 0.9595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153dc84dd97b470b937ed8b496a2a9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, val_loss: 0.3519, val_cohen: 0.8723\n",
      "Sat Jul  4 13:56:18 2020 Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6032827e744ccab275a42102e11b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train_loss: 0.0871, train_cohen: 0.9635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938ddd40e8cc4bba917b5e5eb5210c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, val_loss: 0.3558, val_cohen: 0.8800\n",
      "Sat Jul  4 15:05:06 2020 Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bb287fcd684525ac24a9896d66150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train_loss: 0.0762, train_cohen: 0.9696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e790399c8a5b442bafe2c6fa5df96979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, val_loss: 0.3359, val_cohen: 0.8798\n",
      "Sat Jul  4 16:13:45 2020 Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0007485cb88841c7b62dc30b056d2ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train_loss: 0.0725, train_cohen: 0.9717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fd60d0c8b6435cb2210f025f7ed781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, val_loss: 0.3386, val_cohen: 0.8811\n",
      "Sat Jul  4 17:22:22 2020 Epoch: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed057bb386d4cb592d4678d1a0ba11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train_loss: 0.0681, train_cohen: 0.9746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25fc104f63c47518df3f5e5cf5fc9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, val_loss: 0.3248, val_cohen: 0.8886\n",
      "Sat Jul  4 18:30:58 2020 Epoch: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efec0b8ea63449d7873cc698c59d18d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train_loss: 0.0705, train_cohen: 0.9735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c110a3db0604c09ae9707c733525730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, val_loss: 0.3380, val_cohen: 0.8854\n",
      "Sat Jul  4 19:39:43 2020 Epoch: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bf81aed92747d0a59f4d514d562a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train_loss: 0.0739, train_cohen: 0.9715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3ac5500caa4426a4004a32561a7f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, val_loss: 0.3683, val_cohen: 0.8762\n",
      "Sat Jul  4 20:48:30 2020 Epoch: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ff9f39de844499b7cb5d5e3130db09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1bd81551cddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-9c5b24635a6c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cohen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}, train_loss: {train_loss:.4f}, train_cohen: {train_cohen:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-707266c1060b>\u001b[0m in \u001b[0;36mtrain_on\u001b[0;34m(dl, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(60)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
